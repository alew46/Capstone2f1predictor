{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9989da3e",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Using my scaled data, complete with the features I engineered in the previous step, I now want to try a few different models and evaluate their performance while also evaluating the performance of each type of model using different sets of parameters. Based on the nature of the question, I know I want to limit my evaluation to supervised learning models.\n",
    "\n",
    "A grid search and some cross validation will be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbab0430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#ignore warning messages to ensure clean outputs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import utilities for train/test split, CV, and model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#import model packages to try\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33746469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csv/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ef2f3",
   "metadata": {},
   "source": [
    "### Splitting into Test & Train Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f588ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['positionOrder']\n",
    "X = df.drop(columns = ['positionOrder'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133eed76",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce6c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_scaler = scaler.fit(X_train)\n",
    "X_train = x_scaler.fit_transform(X_train)\n",
    "X_test = x_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6961aec",
   "metadata": {},
   "source": [
    "### Model 1: Linear Regression\n",
    "\n",
    "#### Parameter Tuning With Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ebce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.158389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.183893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.214765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.267785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.351007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_parameter  Accuracy\n",
       "0        0.001  0.158389\n",
       "1        0.010  0.183893\n",
       "2        0.100  0.214765\n",
       "3        1.000  0.267785\n",
       "4       10.000  0.319463\n",
       "5      100.000  0.351007"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "table = pd.DataFrame(columns = ['C_parameter','Accuracy'])\n",
    "table['C_parameter'] = C_param_range\n",
    "\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    \n",
    "    # Apply logistic regression model to training data\n",
    "    Logreg = LogisticRegression(C = i,random_state = 42)\n",
    "    Logreg.fit(X_train,y_train)\n",
    "    \n",
    "    # Predict using model\n",
    "    y_pred_lr = Logreg.predict(X_test)\n",
    "    \n",
    "    # Saving accuracy score in table\n",
    "    table.iloc[j,1] = accuracy_score(y_test,y_pred_lr)\n",
    "    j += 1\n",
    "    \n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "733463ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logreg = LogisticRegression(C = 100, random_state = 42)\n",
    "Logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cddca7",
   "metadata": {},
   "source": [
    "#### Cross Validation & Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08a63bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23825503 0.22147651 0.2114094  0.22147651 0.21812081]\n",
      "Mean cross validation test score: 0.22214765100671144\n",
      "Mean cross validation train score: 0.3303597122302159\n",
      "Standard deviation in cv test scores: 0.008852957018975111\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test = cross_val_score(Logreg, X_test, y_test, cv=5, scoring='accuracy')\n",
    "cv_scores_train = cross_val_score(Logreg, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_lr_test= cv_scores_test.mean()\n",
    "cv_scores_lr_train= cv_scores_train.mean()\n",
    "cv_scores_std_test_lr= cv_scores_test.std()\n",
    "\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_lr_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_lr_train))\n",
    "print ('Standard deviation in cv test scores: ' +str(cv_scores_std_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be13926",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest\n",
    "\n",
    "#### Parameter Tuning With Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af90e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.360403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.343624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.34094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>0.348322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>750</td>\n",
       "      <td>0.368456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>0.356376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_parameter  Accuracy\n",
       "0           10  0.360403\n",
       "1          100  0.343624\n",
       "2          300   0.34094\n",
       "3          500  0.348322\n",
       "4          750  0.368456\n",
       "5          800  0.356376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators_param_range = [10, 100, 300, 500, 750, 800]\n",
    "\n",
    "table = pd.DataFrame(columns = ['n_parameter','Accuracy'])\n",
    "table['n_parameter'] = n_estimators_param_range\n",
    "\n",
    "j = 0\n",
    "for i in C_param_range:\n",
    "    rf = RandomForestClassifier(bootstrap=True,n_estimators=100,criterion='entropy')\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "    \n",
    "    table.iloc[j,1] = accuracy_score(y_test,y_pred_rf)\n",
    "    j += 1\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5663bdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=750, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, n_estimators=750, criterion='entropy', random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df345444",
   "metadata": {},
   "source": [
    "#### Cross Validation & Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14678620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33221477 0.34899329 0.31208054 0.30201342 0.2885906 ]\n",
      "Mean cross validation test score: 0.31677852348993285\n",
      "Mean cross validation train score: 0.361726618705036\n",
      "Standard deviation in cv test scores: 0.021497472990667062\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test = cross_val_score(rf, X_test, y_test, cv=5, scoring='accuracy')\n",
    "cv_scores_train = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_rf_test = cv_scores_test.mean()\n",
    "cv_scores_rf_train = cv_scores_train.mean()\n",
    "cv_scores_std_test_rf = cv_scores_test.std()\n",
    "\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_rf_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_rf_train))\n",
    "print ('Standard deviation in cv test scores: ' +str(cv_scores_std_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5988924",
   "metadata": {},
   "source": [
    "### Model 3: Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08fd231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(subsample=0.8, learning_rate=0.05 , n_estimators=160, random_state=5, max_depth=9, max_leaf_nodes=100)\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gbc = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28bc0d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49328859 0.52684564 0.48993289 0.49328859 0.47651007]\n",
      "Mean cross validation test score: 0.4959731543624161\n",
      "Mean cross validation train score: 0.5315107913669065\n",
      "Standard deviation in cv test scores: 0.016630217038072295\n"
     ]
    }
   ],
   "source": [
    "cv_scores_test = cross_val_score(gbc, X_test, y_test, cv=5, scoring='accuracy')\n",
    "cv_scores_train = cross_val_score(gbc, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(cv_scores_test)\n",
    "\n",
    "cv_scores_gbc_test = cv_scores_test.mean()\n",
    "cv_scores_gbc_train = cv_scores_train.mean()\n",
    "cv_scores_std_test_gbc = cv_scores_test.std()\n",
    "\n",
    "print ('Mean cross validation test score: ' +str(cv_scores_gbc_test))\n",
    "print ('Mean cross validation train score: ' +str(cv_scores_gbc_train))\n",
    "print ('Standard deviation in cv test scores: ' +str(cv_scores_std_test_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed1d5d",
   "metadata": {},
   "source": [
    "### Comparing Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c90977e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Model accuracy score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.351007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.364430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.512081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm  Model accuracy score\n",
       "0  Logistic Regression              0.351007\n",
       "1        Random Forest              0.364430\n",
       "2       Gradient Boost              0.512081"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLabels = [ 'Logistic Regression', 'Random Forest','Gradient Boost']\n",
    "\n",
    "Accuracy_lr=Logreg.score(X_test,y_test)\n",
    "Accuracy_rf=rf.score(X_test,y_test)\n",
    "Accuracy_gbc=gbc.score(X_test,y_test)\n",
    "\n",
    "Accuracy_score = [Accuracy_lr, Accuracy_rf, Accuracy_gbc]\n",
    "\n",
    "accuracy_table = pd.DataFrame(list(zip(myLabels, Accuracy_score)), \n",
    "               columns =['Algorithm', 'Model accuracy score']) \n",
    "\n",
    "accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206fb2e0",
   "metadata": {},
   "source": [
    "Based on these accuracy scores, it's clear that Gradient Boost significantly outperforms the other models tested. All models outperform random choice, which would roughly equate to 1/20 - 1/22 (depedning on how many drivers are participating in the average Grand Prix race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a15368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
